{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d61f51",
   "metadata": {},
   "source": [
    "This code is from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa871dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "EMBEDDING_MODEL = 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "LANGUAGE_MODEL = 'hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF'\n",
    "\n",
    "# Each element in the VECTOR_DB will be a tuple (chunk, embedding)\n",
    "# The embedding is a list of floats, for example: [0.1, 0.04, -0.34, 0.21, ...]\n",
    "VECTOR_DB = []\n",
    "\n",
    "def add_chunk_to_database(chunk):\n",
    "  embedding = ollama.embed(model=EMBEDDING_MODEL, input=chunk)['embeddings'][0]\n",
    "  VECTOR_DB.append((chunk, embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23aea603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 entries\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "with open('test.txt', 'r',encoding=\"utf-8\") as file:\n",
    "  dataset = file.readlines()\n",
    "  print(f'Loaded {len(dataset)} entries')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3851251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added chunk 1/7 to the database\n",
      "Added chunk 2/7 to the database\n",
      "Added chunk 3/7 to the database\n",
      "Added chunk 4/7 to the database\n",
      "Added chunk 5/7 to the database\n",
      "Added chunk 6/7 to the database\n",
      "Added chunk 7/7 to the database\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(dataset):\n",
    "  add_chunk_to_database(chunk)\n",
    "  print(f'Added chunk {i+1}/{len(dataset)} to the database')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a392a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "  dot_product = sum([x * y for x, y in zip(a, b)])\n",
    "  norm_a = sum([x ** 2 for x in a]) ** 0.5\n",
    "  norm_b = sum([x ** 2 for x in b]) ** 0.5\n",
    "  return dot_product / (norm_a * norm_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e1ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_n=3):\n",
    "  query_embedding = ollama.embed(model=EMBEDDING_MODEL, input=query)['embeddings'][0]\n",
    "  # temporary list to store (chunk, similarity) pairs\n",
    "  similarities = []\n",
    "  for chunk, embedding in VECTOR_DB:\n",
    "    similarity = cosine_similarity(query_embedding, embedding)\n",
    "    similarities.append((chunk, similarity))\n",
    "  # sort by similarity in descending order, because higher similarity means more relevant chunks\n",
    "  similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "  # finally, return the top N most relevant chunks\n",
    "  return similarities[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a44ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved knowledge:\n",
      " - (similarity: 0.79) \"Cyber security is primarily about people, processes, and technologies working together to encompass the full range of threat reduction, vulnerability reduction, deterrence, international engagement, incident response, resiliency, and recovery policies and activities, including computer network operations, information assurance, law enforcement, etc.\n",
      " - (similarity: 0.63) Hey , Mike . You've been surfing the Net for quite a while . What on earth are you searching for ? __eou__ It's something relative hackers . I often hear people talking about them , but I don't know much about them . __eou__ Well , roughly speaking , a hacker is a computer buff . __eou__ You mean a guy using enthusiastic and knowledgeable about the computer ? __eou__ You can say that . __eou__ But why are people always having such a negative attitude towards them ? __eou__ They must have mixed hackers with crackers . __eou__ What is crackers then ? __eou__ There is another group of people who loudly call themselves hackers , but they aren't . They break into computers and break the phone system . Real hackers call these people crackers , and want nothing to do with them . __eou__ So they are two totally different concepts . __eou__ Well , the real hackers mostly think crackers are lazy , irresponsible and not very bright , and feel that being able to break security does make you a hacker any more than being able to start cars without keys makes you an automotive engineer . Unfortunately , many journalists and writers have been fooled into using the word hacker to describe crackers . This irritates real hackers to no end . __eou__ I see . Then the basic different is , hackers build things , crackers break them . __eou__ You got it . __eou__ Thanks a lot . __eou__ You are welcome . __eou__\n",
      "\n",
      " - (similarity: 0.57) Jim , I heard you ’ Ve bought a new computer . __eou__ Yes . Look , it is on my desk . __eou__ Your office looks different with a computer . By the way , is it difficult to use a computer ? __eou__ Not at all . It ’ s a piece of cake . __eou__ A piece of cake ? __eou__ Yes . It ’ s easy and convenient to use a computer . But it takes a long time to really master it . __eou__\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_query = input('Ask me a question: ')\n",
    "retrieved_knowledge = retrieve(input_query)\n",
    "\n",
    "print('Retrieved knowledge:')\n",
    "for chunk, similarity in retrieved_knowledge:\n",
    "  print(f' - (similarity: {similarity:.2f}) {chunk}')\n",
    "\n",
    "instruction_prompt = f'''You are a helpful chatbot.\n",
    "Use only the following pieces of context to answer the question. Don't make up any new information:\n",
    "{'\\n'.join([f' - {chunk}' for chunk, similarity in retrieved_knowledge])}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8dcf5",
   "metadata": {},
   "source": [
    "```\n",
    "    ollama pull hf.co/CompendiumLabs/bge-base-en-v1.5-gguf\n",
    "    ollama pull hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
